{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udnx4fNi1-T3",
        "outputId": "b894b084-e6a0-4d3c-956d-414946c61f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn) (3.5.0)\n",
            "/content/drive/MyDrive\n",
            "fatal: destination path 'PatchTST' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/PatchTST/PatchTST/PatchTST_supervised\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!pip3 install scikit_learn\n",
        "\n",
        "\n",
        "\n",
        "#%cd drive/MyDrive/\n",
        "import os\n",
        "rel_directory_path = 'PatchTST'\n",
        "if not os.path.exists(rel_directory_path):\n",
        "    os.makedirs(rel_directory_path)\n",
        "\n",
        "os.chdir(rel_directory_path)\n",
        "!git clone https://github.com/yuqinie98/PatchTST.git\n",
        "%cd PatchTST/PatchTST_supervised"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.multiprocessing as mp\n",
        "mp.set_start_method('spawn')"
      ],
      "metadata": {
        "id": "eRVSBYmRu-5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!chmod a+x scripts/PatchTST/etth1.sh\n",
        "#!bash scripts/PatchTST/etth1.sh"
      ],
      "metadata": {
        "id": "LonWxWrY4ZRW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLgKdjkddnmj",
        "outputId": "bcb2b11a-bafb-4047-95fa-b74a2b97d56b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ar_all.pkl     dataset\tlayers\tPatchTST\t  result.txt\t  test_results\n",
            "checkpoints    exp\tlogs\trequirements.txt  run_longExp.py  utils\n",
            "data_provider  Formers\tmodels\tresults\t\t  scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "mZeS5RGesqYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from utils.timefeatures import time_features\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Dataset_ETT_hour(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], axis=1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_ETT_minute(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTm1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='t'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], axis=1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = torch.from_numpy(data[border1:border2]).to(device='cuda:0')\n",
        "        self.data_y = torch.from_numpy(data[border1:border2]).to(device='cuda:0')\n",
        "        self.data_stamp = torch.from_numpy(data_stamp).to(device='cuda:0')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Custom(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        cols = list(df_raw.columns)\n",
        "        cols.remove(self.target)\n",
        "        cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        # print(cols)\n",
        "        num_train = int(len(df_raw) * 0.7)\n",
        "        num_test = int(len(df_raw) * 0.2)\n",
        "        num_vali = len(df_raw) - num_train - num_test\n",
        "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
        "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            # print(self.scaler.mean_)\n",
        "            # exit()\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], axis=1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = torch.from_numpy(data[border1:border2]).to(device='cuda:0')\n",
        "        self.data_y = torch.from_numpy(data[border1:border2]).to(device='cuda:0')\n",
        "        self.data_stamp = torch.from_numpy(data_stamp).to(device='cuda:0')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Pred(Dataset):\n",
        "    def __init__(self, root_path, flag='pred', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['pred']\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.inverse = inverse\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.cols = cols\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        if self.cols:\n",
        "            cols = self.cols.copy()\n",
        "            cols.remove(self.target)\n",
        "        else:\n",
        "            cols = list(df_raw.columns)\n",
        "            cols.remove(self.target)\n",
        "            cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        border1 = len(df_raw) - self.seq_len\n",
        "        border2 = len(df_raw)\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            self.scaler.fit(df_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        tmp_stamp = df_raw[['date']][border1:border2]\n",
        "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
        "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
        "\n",
        "        df_stamp = pd.DataFrame(columns=['date'])\n",
        "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], axis=1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        if self.inverse:\n",
        "            self.data_y = df_data.values[border1:border2]\n",
        "        else:\n",
        "            self.data_y = data[border1:border2]\n",
        "\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        if self.inverse:\n",
        "            seq_y = self.data_x[r_begin:r_begin + self.label_len]\n",
        "        else:\n",
        "            seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)"
      ],
      "metadata": {
        "id": "McZecLyIhLPO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_dict = {\n",
        "    'ETTh1': Dataset_ETT_hour,\n",
        "    'ETTh2': Dataset_ETT_hour,\n",
        "    'ETTm1': Dataset_ETT_minute,\n",
        "    'ETTm2': Dataset_ETT_minute,\n",
        "    'custom': Dataset_Custom,\n",
        "}\n",
        "\n",
        "\n",
        "def data_provider(args, flag):\n",
        "    Data = data_dict[args.data]\n",
        "    timeenc = 0 if args.embed != 'timeF' else 1\n",
        "\n",
        "    if flag == 'test':\n",
        "        shuffle_flag = False\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "    elif flag == 'pred':\n",
        "        shuffle_flag = False\n",
        "        drop_last = False\n",
        "        batch_size = 1\n",
        "        freq = args.freq\n",
        "        Data = Dataset_Pred\n",
        "    else:\n",
        "        shuffle_flag = True\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "\n",
        "    data_set = Data(\n",
        "        root_path=args.root_path,\n",
        "        data_path=args.data_path,\n",
        "        flag=flag,\n",
        "        size=[args.seq_len, args.label_len, args.pred_len],\n",
        "        features=args.features,\n",
        "        target=args.target,\n",
        "        timeenc=timeenc,\n",
        "        freq=freq\n",
        "    )\n",
        "    print(flag, len(data_set))\n",
        "    data_loader = DataLoader(\n",
        "        data_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle_flag,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=drop_last)\n",
        "    return data_set, data_loader"
      ],
      "metadata": {
        "id": "qmXpk6qngcOK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "wcXQ-n5Bsl55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#__all__ = ['Transpose', 'get_activation_fn', 'moving_avg', 'series_decomp', 'PositionalEncoding', 'SinCosPosEncoding', 'Coord2dPosEncoding', 'Coord1dPosEncoding', 'positional_encoding']\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "\n",
        "class Transpose(nn.Module):\n",
        "    def __init__(self, *dims, contiguous=False):\n",
        "        super().__init__()\n",
        "        self.dims, self.contiguous = dims, contiguous\n",
        "    def forward(self, x):\n",
        "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
        "        else: return x.transpose(*self.dims)\n",
        "\n",
        "\n",
        "def get_activation_fn(activation):\n",
        "    if callable(activation): return activation()\n",
        "    elif activation.lower() == \"relu\": return nn.ReLU()\n",
        "    elif activation.lower() == \"gelu\": return nn.GELU()\n",
        "    raise ValueError(f'{activation} is not available. You can use \"relu\", \"gelu\", or a callable')\n",
        "\n",
        "\n",
        "# decomposition\n",
        "\n",
        "class moving_avg(nn.Module):\n",
        "    \"\"\"\n",
        "    Moving average block to highlight the trend of time series\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super(moving_avg, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class series_decomp(nn.Module):\n",
        "    \"\"\"\n",
        "    Series decomposition block\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        super(series_decomp, self).__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "\n",
        "\n",
        "# pos_encoding\n",
        "\n",
        "def PositionalEncoding(q_len, d_model, normalize=True):\n",
        "    pe = torch.zeros(q_len, d_model)\n",
        "    position = torch.arange(0, q_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    if normalize:\n",
        "        pe = pe - pe.mean()\n",
        "        pe = pe / (pe.std() * 10)\n",
        "    return pe\n",
        "\n",
        "SinCosPosEncoding = PositionalEncoding\n",
        "\n",
        "def Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True, eps=1e-3, verbose=False):\n",
        "    x = .5 if exponential else 1\n",
        "    i = 0\n",
        "    for i in range(100):\n",
        "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, d_model).reshape(1, -1) ** x) - 1\n",
        "        pv(f'{i:4.0f}  {x:5.3f}  {cpe.mean():+6.3f}', verbose)\n",
        "        if abs(cpe.mean()) <= eps: break\n",
        "        elif cpe.mean() > eps: x += .001\n",
        "        else: x -= .001\n",
        "        i += 1\n",
        "    if normalize:\n",
        "        cpe = cpe - cpe.mean()\n",
        "        cpe = cpe / (cpe.std() * 10)\n",
        "    return cpe\n",
        "\n",
        "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
        "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
        "    if normalize:\n",
        "        cpe = cpe - cpe.mean()\n",
        "        cpe = cpe / (cpe.std() * 10)\n",
        "    return cpe\n",
        "\n",
        "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
        "    # Positional encoding\n",
        "    if pe == None:\n",
        "        W_pos = torch.empty((q_len, d_model)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "        learn_pe = False\n",
        "    elif pe == 'zero':\n",
        "        W_pos = torch.empty((q_len, 1))\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "    elif pe == 'zeros':\n",
        "        W_pos = torch.empty((q_len, d_model))\n",
        "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
        "    elif pe == 'normal' or pe == 'gauss':\n",
        "        W_pos = torch.zeros((q_len, 1))\n",
        "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
        "    elif pe == 'uniform':\n",
        "        W_pos = torch.zeros((q_len, 1))\n",
        "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
        "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
        "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
        "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n",
        "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n",
        "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, d_model, normalize=True)\n",
        "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
        "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
        "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
      ],
      "metadata": {
        "id": "m654bRnanM2K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code from https://github.com/ts-kim/RevIN, with minor modifications\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RevIN(nn.Module):\n",
        "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
        "        \"\"\"\n",
        "        :param num_features: the number of features or channels\n",
        "        :param eps: a value added for numerical stability\n",
        "        :param affine: if True, RevIN has learnable affine parameters\n",
        "        \"\"\"\n",
        "        super(RevIN, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.affine = affine\n",
        "        self.subtract_last = subtract_last\n",
        "        if self.affine:\n",
        "            self._init_params()\n",
        "\n",
        "    def forward(self, x, mode:str):\n",
        "        if mode == 'norm':\n",
        "            self._get_statistics(x)\n",
        "            x = self._normalize(x)\n",
        "        elif mode == 'denorm':\n",
        "            x = self._denormalize(x)\n",
        "        else: raise NotImplementedError\n",
        "        return x\n",
        "\n",
        "    def _init_params(self):\n",
        "        # initialize RevIN params: (C,)\n",
        "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
        "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
        "\n",
        "    def _get_statistics(self, x):\n",
        "        dim2reduce = tuple(range(1, x.ndim-1))\n",
        "        if self.subtract_last:\n",
        "            self.last = x[:,-1,:].unsqueeze(1)\n",
        "        else:\n",
        "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
        "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
        "\n",
        "    def _normalize(self, x):\n",
        "        if self.subtract_last:\n",
        "            x = x - self.last\n",
        "        else:\n",
        "            x = x - self.mean\n",
        "        x = x / self.stdev\n",
        "        if self.affine:\n",
        "            x = x * self.affine_weight\n",
        "            x = x + self.affine_bias\n",
        "        return x\n",
        "\n",
        "    def _denormalize(self, x):\n",
        "        if self.affine:\n",
        "            x = x - self.affine_bias\n",
        "            x = x / (self.affine_weight + self.eps*self.eps)\n",
        "        x = x * self.stdev\n",
        "        if self.subtract_last:\n",
        "            x = x + self.last\n",
        "        else:\n",
        "            x = x + self.mean\n",
        "        return x"
      ],
      "metadata": {
        "id": "4fWwI57FwMsn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell\n",
        "from typing import Callable, Optional\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "#from collections import OrderedDict\n",
        "#from layers.PatchTST_layers import *\n",
        "#from layers.RevIN import RevIN\n",
        "\n",
        "# Cell\n",
        "class PatchTST_backbone(nn.Module):\n",
        "    def __init__(self, c_in:int, context_window:int, target_window:int, patch_len:int, stride:int, max_seq_len:Optional[int]=1024,\n",
        "                 n_layers:int=3, d_model=128, n_heads=16, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
        "                 d_ff:int=256, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0., act:str=\"gelu\", key_padding_mask:bool='auto',\n",
        "                 padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
        "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0., head_dropout = 0, padding_patch = None,\n",
        "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False,\n",
        "                 verbose:bool=False, **kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.alpha = 0.0\n",
        "        self.raw = False\n",
        "        # RevIn\n",
        "        self.revin = revin\n",
        "        self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
        "\n",
        "        # Patching\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "        self.padding_patch = padding_patch\n",
        "        patch_num = int((context_window - patch_len)/stride + 1)\n",
        "        if padding_patch == 'end': # can be modified to general case\n",
        "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride))\n",
        "            patch_num += 1\n",
        "\n",
        "        # Backbone\n",
        "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
        "                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n",
        "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
        "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
        "                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)\n",
        "\n",
        "        # Head\n",
        "        self.head_nf = d_model * patch_num\n",
        "        self.n_vars = c_in\n",
        "        self.pretrain_head = pretrain_head\n",
        "        self.head_type = head_type\n",
        "        self.individual = individual\n",
        "        self.target_window = target_window\n",
        "        n_vars_head = self.n_vars\n",
        "        if self.raw:\n",
        "            self.mix = nn.Linear(self.n_vars*self.target_window*2, self.n_vars*self.target_window)\n",
        "            n_vars_head = self.n_vars*2\n",
        "        if self.pretrain_head:\n",
        "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
        "        elif head_type == 'flatten':\n",
        "            self.head = Flatten_Head(self.individual, n_vars_head, self.head_nf, target_window, head_dropout=head_dropout)\n",
        "\n",
        "\n",
        "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
        "        # norm\n",
        "        if self.raw:\n",
        "          z_orig = z\n",
        "          batch_size = z.shape[0]\n",
        "        if self.revin:\n",
        "            z = z.permute(0,2,1)\n",
        "            z = self.revin_layer(z, 'norm')\n",
        "            z = z.permute(0,2,1)\n",
        "        if self.raw:\n",
        "            z = torch.cat((z, z_orig), dim=1)\n",
        "        # do patching\n",
        "        if self.padding_patch == 'end':\n",
        "            z = self.padding_patch_layer(z)\n",
        "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
        "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
        "\n",
        "        # model\n",
        "        z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
        "        z = self.head(z)                                                                    # z: [bs x nvars x target_window]\n",
        "\n",
        "        # denorm\n",
        "        if self.raw:\n",
        "            z_orig = z\n",
        "            z = z[:,:self.n_vars,:]\n",
        "        if self.revin:\n",
        "            z = z.permute(0,2,1)\n",
        "            z = self.revin_layer(z, 'denorm')\n",
        "            z = z.permute(0,2,1)\n",
        "        if self.raw:\n",
        "            #z0 = z\n",
        "            #z = torch.cat((z, z_orig[:, self.n_vars:, :]), dim=1)\n",
        "            #z = z.reshape(batch_size, -1)\n",
        "            #z = self.mix(z)\n",
        "            #z = z.reshape(batch_size, self.n_vars, -1)\n",
        "            #z = z + z0\n",
        "\n",
        "            #z = (z + z_orig[:, self.n_vars:, :])/2\n",
        "\n",
        "            z = z + self.alpha*z_orig[:, self.n_vars:, :]\n",
        "\n",
        "        return z\n",
        "\n",
        "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
        "        return nn.Sequential(nn.Dropout(dropout),\n",
        "                    nn.Conv1d(head_nf, vars, 1)\n",
        "                    )\n",
        "\n",
        "\n",
        "class Flatten_Head(nn.Module):\n",
        "    def __init__(self, individual, n_vars, nf, target_window, head_dropout=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.individual = individual\n",
        "        self.n_vars = n_vars\n",
        "\n",
        "        if self.individual:\n",
        "            self.linears = nn.ModuleList()\n",
        "            self.dropouts = nn.ModuleList()\n",
        "            self.flattens = nn.ModuleList()\n",
        "            for i in range(self.n_vars):\n",
        "                self.flattens.append(nn.Flatten(start_dim=-2))\n",
        "                self.linears.append(nn.Linear(nf, target_window))\n",
        "                self.dropouts.append(nn.Dropout(head_dropout))\n",
        "        else:\n",
        "            self.flatten = nn.Flatten(start_dim=-2)\n",
        "            self.linear = nn.Linear(nf, target_window)\n",
        "            self.dropout = nn.Dropout(head_dropout)\n",
        "\n",
        "    def forward(self, x):                                 # x: [bs x nvars x d_model x patch_num]\n",
        "        if self.individual:\n",
        "            x_out = []\n",
        "            for i in range(self.n_vars):\n",
        "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x d_model * patch_num]\n",
        "                z = self.linears[i](z)                    # z: [bs x target_window]\n",
        "                z = self.dropouts[i](z)\n",
        "                x_out.append(z)\n",
        "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x target_window]\n",
        "        else:\n",
        "            x = self.flatten(x)\n",
        "            x = self.linear(x)\n",
        "            x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TSTiEncoder(nn.Module):  #i means channel-independent\n",
        "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
        "                 n_layers=3, d_model=128, n_heads=16, d_k=None, d_v=None,\n",
        "                 d_ff=256, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
        "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
        "                 pe='zeros', learn_pe=True, verbose=False, **kwargs):\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_num = patch_num\n",
        "        self.patch_len = patch_len\n",
        "\n",
        "        # Input encoding\n",
        "        q_len = patch_num\n",
        "        self.W_P = nn.Linear(patch_len, d_model)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
        "        self.seq_len = q_len\n",
        "\n",
        "        # Positional encoding\n",
        "        self.W_pos = positional_encoding(pe, learn_pe, q_len, d_model)\n",
        "\n",
        "        # Residual dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
        "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
        "\n",
        "\n",
        "    def forward(self, x) -> Tensor:                                              # x: [bs x nvars x patch_len x patch_num]\n",
        "\n",
        "        n_vars = x.shape[1]\n",
        "        # Input encoding\n",
        "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
        "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x d_model]\n",
        "\n",
        "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x d_model]\n",
        "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x d_model]\n",
        "\n",
        "        # Encoder\n",
        "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x d_model]\n",
        "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x d_model]\n",
        "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x d_model x patch_num]\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "# Cell\n",
        "class TSTEncoder(nn.Module):\n",
        "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None,\n",
        "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
        "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm,\n",
        "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
        "                                                      activation=activation, res_attention=res_attention,\n",
        "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
        "        self.res_attention = res_attention\n",
        "\n",
        "    def forward(self, src:Tensor, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "        output = src\n",
        "        scores = None\n",
        "        if self.res_attention:\n",
        "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "            return output\n",
        "        else:\n",
        "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "            return output\n",
        "\n",
        "\n",
        "\n",
        "class TSTEncoderLayer(nn.Module):\n",
        "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=256, store_attn=False,\n",
        "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
        "        super().__init__()\n",
        "        assert not d_model%n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
        "        d_k = d_model // n_heads if d_k is None else d_k\n",
        "        d_v = d_model // n_heads if d_v is None else d_v\n",
        "\n",
        "        # Multi-Head attention\n",
        "        self.res_attention = res_attention\n",
        "        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, attn_dropout=attn_dropout, proj_dropout=dropout, res_attention=res_attention)\n",
        "\n",
        "        # Add & Norm\n",
        "        self.dropout_attn = nn.Dropout(dropout)\n",
        "        if \"batch\" in norm.lower():\n",
        "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
        "        else:\n",
        "            self.norm_attn = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Position-wise Feed-Forward\n",
        "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias),\n",
        "                                get_activation_fn(activation),\n",
        "                                nn.Dropout(dropout),\n",
        "                                nn.Linear(d_ff, d_model, bias=bias))\n",
        "\n",
        "        # Add & Norm\n",
        "        self.dropout_ffn = nn.Dropout(dropout)\n",
        "        if \"batch\" in norm.lower():\n",
        "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
        "        else:\n",
        "            self.norm_ffn = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.pre_norm = pre_norm\n",
        "        self.store_attn = store_attn\n",
        "\n",
        "\n",
        "    def forward(self, src:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None) -> Tensor:\n",
        "\n",
        "        # Multi-Head attention sublayer\n",
        "        if self.pre_norm:\n",
        "            src = self.norm_attn(src)\n",
        "        ## Multi-Head attention\n",
        "        if self.res_attention:\n",
        "            src2, attn, scores = self.self_attn(src, src, src, prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        else:\n",
        "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        if self.store_attn:\n",
        "            self.attn = attn\n",
        "        ## Add & Norm\n",
        "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
        "        if not self.pre_norm:\n",
        "            src = self.norm_attn(src)\n",
        "\n",
        "        # Feed-forward sublayer\n",
        "        if self.pre_norm:\n",
        "            src = self.norm_ffn(src)\n",
        "        ## Position-wise Feed-Forward\n",
        "        src2 = self.ff(src)\n",
        "        ## Add & Norm\n",
        "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
        "        if not self.pre_norm:\n",
        "            src = self.norm_ffn(src)\n",
        "\n",
        "        if self.res_attention:\n",
        "            return src, scores\n",
        "        else:\n",
        "            return src\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class _MultiheadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_k=None, d_v=None, res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
        "        \"\"\"Multi Head Attention Layer\n",
        "        Input shape:\n",
        "            Q:       [batch_size (bs) x max_q_len x d_model]\n",
        "            K, V:    [batch_size (bs) x q_len x d_model]\n",
        "            mask:    [q_len x q_len]\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        d_k = d_model // n_heads if d_k is None else d_k\n",
        "        d_v = d_model // n_heads if d_v is None else d_v\n",
        "\n",
        "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=qkv_bias)\n",
        "\n",
        "        # Scaled Dot-Product Attention (multiple heads)\n",
        "        self.res_attention = res_attention\n",
        "        self.sdp_attn = _ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout, res_attention=self.res_attention, lsa=lsa)\n",
        "\n",
        "        # Poject output\n",
        "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(proj_dropout))\n",
        "\n",
        "\n",
        "    def forward(self, Q:Tensor, K:Optional[Tensor]=None, V:Optional[Tensor]=None, prev:Optional[Tensor]=None,\n",
        "                key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "\n",
        "        bs = Q.size(0)\n",
        "        if K is None: K = Q\n",
        "        if V is None: V = Q\n",
        "\n",
        "        # Linear (+ split in multiple heads)\n",
        "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
        "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
        "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
        "\n",
        "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
        "        if self.res_attention:\n",
        "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        else:\n",
        "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
        "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
        "\n",
        "        # back to the original inputs dimensions\n",
        "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
        "        output = self.to_out(output)\n",
        "\n",
        "        if self.res_attention: return output, attn_weights, attn_scores\n",
        "        else: return output, attn_weights\n",
        "\n",
        "\n",
        "class _ScaledDotProductAttention(nn.Module):\n",
        "    r\"\"\"Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
        "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
        "    by Lee et al, 2021)\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
        "        super().__init__()\n",
        "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
        "        self.res_attention = res_attention\n",
        "        head_dim = d_model // n_heads\n",
        "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
        "        self.lsa = lsa\n",
        "\n",
        "    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):\n",
        "        '''\n",
        "        Input shape:\n",
        "            q               : [bs x n_heads x max_q_len x d_k]\n",
        "            k               : [bs x n_heads x d_k x seq_len]\n",
        "            v               : [bs x n_heads x seq_len x d_v]\n",
        "            prev            : [bs x n_heads x q_len x seq_len]\n",
        "            key_padding_mask: [bs x seq_len]\n",
        "            attn_mask       : [1 x seq_len x seq_len]\n",
        "        Output shape:\n",
        "            output:  [bs x n_heads x q_len x d_v]\n",
        "            attn   : [bs x n_heads x q_len x seq_len]\n",
        "            scores : [bs x n_heads x q_len x seq_len]\n",
        "        '''\n",
        "\n",
        "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
        "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
        "\n",
        "        # Add pre-softmax attention scores from the previous layer (optional)\n",
        "        if prev is not None: attn_scores = attn_scores + prev\n",
        "\n",
        "        # Attention mask (optional)\n",
        "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
        "            if attn_mask.dtype == torch.bool:\n",
        "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
        "            else:\n",
        "                attn_scores += attn_mask\n",
        "\n",
        "        # Key padding mask (optional)\n",
        "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
        "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
        "\n",
        "        # normalize the attention weights\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
        "        attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "        # compute the new values given the attention weights\n",
        "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
        "\n",
        "        if self.res_attention: return output, attn_weights, attn_scores\n",
        "        else: return output, attn_weights\n"
      ],
      "metadata": {
        "id": "e3XpJ9eUmG0J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#__all__ = ['PatchTST']\n",
        "\n",
        "# Cell\n",
        "from typing import Callable, Optional\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "#from layers.PatchTST_backbone import PatchTST_backbone\n",
        "#from layers.PatchTST_layers import series_decomp\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, configs, max_seq_len:Optional[int]=1024, d_k:Optional[int]=None, d_v:Optional[int]=None, norm:str='BatchNorm', attn_dropout:float=0.,\n",
        "                 act:str=\"gelu\", key_padding_mask:bool='auto',padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True,\n",
        "                 pre_norm:bool=False, store_attn:bool=False, pe:str='zeros', learn_pe:bool=True, pretrain_head:bool=False, head_type = 'flatten', verbose:bool=False, **kwargs):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # load parameters\n",
        "        c_in = configs.enc_in\n",
        "        context_window = configs.seq_len\n",
        "        target_window = configs.pred_len\n",
        "\n",
        "        n_layers = configs.e_layers\n",
        "        n_heads = configs.n_heads\n",
        "        d_model = configs.d_model\n",
        "        d_ff = configs.d_ff\n",
        "        dropout = configs.dropout\n",
        "        fc_dropout = configs.fc_dropout\n",
        "        head_dropout = configs.head_dropout\n",
        "\n",
        "        individual = configs.individual\n",
        "\n",
        "        patch_len = configs.patch_len\n",
        "        stride = configs.stride\n",
        "        padding_patch = configs.padding_patch\n",
        "\n",
        "        revin = configs.revin\n",
        "        affine = configs.affine\n",
        "        subtract_last = configs.subtract_last\n",
        "\n",
        "        kernel_size = configs.kernel_size\n",
        "\n",
        "\n",
        "        # model\n",
        "        self.model = PatchTST_backbone(c_in=c_in, context_window = context_window, target_window=target_window, patch_len=patch_len, stride=stride,\n",
        "                              max_seq_len=max_seq_len, n_layers=n_layers, d_model=d_model,\n",
        "                              n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout,\n",
        "                              dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
        "                              attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
        "                              pe=pe, learn_pe=learn_pe, fc_dropout=fc_dropout, head_dropout=head_dropout, padding_patch = padding_patch,\n",
        "                              pretrain_head=pretrain_head, head_type=head_type, individual=individual, revin=revin, affine=affine,\n",
        "                              subtract_last=subtract_last, verbose=verbose, **kwargs)\n",
        "\n",
        "\n",
        "    def forward(self, x):           # x: [Batch, Input length, Channel]\n",
        "        x = x.permute(0,2,1)    # x: [Batch, Channel, Input length]\n",
        "        x = self.model(x)\n",
        "        x = x.permute(0,2,1)    # x: [Batch, Input length, Channel]\n",
        "        return x"
      ],
      "metadata": {
        "id": "V5Dw_0Z7jZcL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment"
      ],
      "metadata": {
        "id": "9CFy7DU3sZLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Exp_Basic(object):\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.device = self._acquire_device()\n",
        "        self.model = self._build_model().to(self.device)\n",
        "        self.model_res = self._build_model_res().to(self.device)\n",
        "\n",
        "    def _build_model(self):\n",
        "        raise NotImplementedError\n",
        "        return None\n",
        "\n",
        "    def _build_model_res(self):\n",
        "        raise NotImplementedError\n",
        "        return None\n",
        "\n",
        "    def _acquire_device(self):\n",
        "        if self.args.use_gpu:\n",
        "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
        "                self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n",
        "            device = torch.device('cuda:{}'.format(self.args.gpu))\n",
        "            print('Use GPU: cuda:{}'.format(self.args.gpu))\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "            print('Use CPU')\n",
        "        return device\n",
        "\n",
        "    def _get_data(self):\n",
        "        pass\n",
        "\n",
        "    def vali(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    def test(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "WAGnrQOmH5GW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from data_provider.data_factory import data_provider\n",
        "#from exp.exp_basic import Exp_Basic\n",
        "#from models import Informer, Autoformer, Transformer, DLinear, Linear, NLinear, PatchTST\n",
        "from utils.tools import EarlyStopping, adjust_learning_rate, visual, test_params_flop\n",
        "from utils.metrics import metric\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class Exp_Main(Exp_Basic):\n",
        "    def __init__(self, args):\n",
        "        super(Exp_Main, self).__init__(args)\n",
        "\n",
        "    def _build_model(self):\n",
        "        #model_dict = {\n",
        "        #    'Autoformer': Autoformer,\n",
        "        #    'Transformer': Transformer,\n",
        "        #    'Informer': Informer,\n",
        "        #    'DLinear': DLinear,\n",
        "        #    'NLinear': NLinear,\n",
        "        #    'Linear': Linear,\n",
        "        #    'PatchTST': PatchTST,\n",
        "        #}\n",
        "        #model = model_dict[self.args.model].Model(self.args).float()\n",
        "        if self.args.model == 'PatchTST':\n",
        "            model = Model(self.args).float()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
        "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
        "        return model\n",
        "\n",
        "\n",
        "    def _build_model_res(self):\n",
        "        #model_dict = {\n",
        "        #    'Autoformer': Autoformer,\n",
        "        #    'Transformer': Transformer,\n",
        "        #    'Informer': Informer,\n",
        "        #    'DLinear': DLinear,\n",
        "        #    'NLinear': NLinear,\n",
        "        #    'Linear': Linear,\n",
        "        #    'PatchTST': PatchTST,\n",
        "        #}\n",
        "        #model = model_dict[self.args.model].Model(self.args).float()\n",
        "        if self.args.model == 'PatchTST':\n",
        "            model = Model(self.args).float()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
        "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
        "        model.model.revin = False\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def _get_data(self, flag):\n",
        "        data_set, data_loader = data_provider(self.args, flag)\n",
        "        return data_set, data_loader\n",
        "\n",
        "    def _select_optimizer(self):\n",
        "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _select_optimizer_res(self):\n",
        "        model_optim = optim.Adam(self.model_res.parameters(), lr=self.args.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _select_criterion(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def vali(self, vali_data, vali_loader, criterion):\n",
        "        total_loss = []\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                            outputs = self.model(batch_x)\n",
        "                        else:\n",
        "                            if self.args.output_attention:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                            else:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                        outputs = self.model(batch_x)\n",
        "                        if self.res_active:\n",
        "                            outputs_res = self.model_res(batch_x)\n",
        "                            outputs = outputs + 0.05*outputs_res\n",
        "                    else:\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                if self.args.last_eval:\n",
        "                    batch_y = batch_y[:,-1,:].unsqueeze(1)\n",
        "                    outputs = outputs[:,-1,:].unsqueeze(1)\n",
        "                pred = outputs.detach().cpu()\n",
        "                true = batch_y.detach().cpu()\n",
        "\n",
        "                loss = criterion(pred, true)\n",
        "\n",
        "                total_loss.append(loss)\n",
        "        total_loss = np.average(total_loss)\n",
        "        self.model.train()\n",
        "        print(outputs.shape, batch_y.shape)\n",
        "        return total_loss\n",
        "\n",
        "    def train(self, setting):\n",
        "        self.res_active = False\n",
        "        #pred_len_orig = self.args.pred_len\n",
        "        #self.args.pred_len = pred_len_orig * 2\n",
        "        train_data, train_loader = self._get_data(flag='train')\n",
        "        #self.args.pred_len = pred_len_orig\n",
        "        vali_data, vali_loader = self._get_data(flag='val')\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "\n",
        "        path = os.path.join(self.args.checkpoints, setting)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        time_now = time.time()\n",
        "\n",
        "        train_steps = len(train_loader)\n",
        "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
        "\n",
        "        model_optim = self._select_optimizer()\n",
        "        model_optim_res = self._select_optimizer_res()\n",
        "        criterion = self._select_criterion()\n",
        "\n",
        "        if self.args.use_amp:\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        scheduler = lr_scheduler.OneCycleLR(optimizer = model_optim,\n",
        "                                            steps_per_epoch = train_steps,\n",
        "                                            pct_start = self.args.pct_start,\n",
        "                                            epochs = self.args.train_epochs,\n",
        "                                            max_lr = self.args.learning_rate)\n",
        "\n",
        "        for epoch in range(self.args.train_epochs):\n",
        "            if epoch == self.args.start:\n",
        "                self.res_active = True\n",
        "            iter_count = 0\n",
        "            train_loss = []\n",
        "\n",
        "            self.model.train()\n",
        "            epoch_time = time.time()\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
        "                iter_count += 1\n",
        "                model_optim.zero_grad()\n",
        "                model_optim_res.zero_grad()\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                            outputs = self.model(batch_x)\n",
        "                        else:\n",
        "                            if self.args.output_attention:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                            else:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                        loss = criterion(outputs, batch_y)\n",
        "                        train_loss.append(loss.item())\n",
        "                else:\n",
        "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                            outputs = self.model(batch_x)\n",
        "                            if self.res_active:\n",
        "                                outputs_res = self.model_res(batch_x)\n",
        "                                outputs = outputs + 0.05*outputs_res\n",
        "\n",
        "\n",
        "                    else:\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
        "                    #print(outputs.shape,batch_y.shape, batch_x.shape)\n",
        "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                    #batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                    batch_y_t = batch_y[:, 0:self.args.pred_len, f_dim:].to(self.device)\n",
        "                    if self.args.last_train:\n",
        "                        batch_y_t = batch_y_t[:,-1,:].unsqueeze(1)\n",
        "                        outputs = outputs[:,-1,:].unsqueeze(1)\n",
        "                    loss = criterion(outputs, batch_y_t)\n",
        "                    train_loss.append(loss.item())\n",
        "\n",
        "                if (i + 1) % 100 == 0:\n",
        "                    print(batch_y.shape, batch_y_t.shape)\n",
        "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
        "                    speed = (time.time() - time_now) / iter_count\n",
        "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
        "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "                    iter_count = 0\n",
        "                    time_now = time.time()\n",
        "\n",
        "                if self.args.use_amp:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(model_optim)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                    if self.res_active:\n",
        "                        model_optim_res.step()\n",
        "                    else:\n",
        "                        model_optim.step()\n",
        "\n",
        "\n",
        "                if self.args.lradj == 'TST':\n",
        "                    adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args, printout=False)\n",
        "                    scheduler.step()\n",
        "\n",
        "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "            print(\"alpha: {}\".format(self.model.model.alpha))\n",
        "            train_loss = np.average(train_loss)\n",
        "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
        "            test_loss = self.vali(test_data, test_loader, criterion)\n",
        "\n",
        "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
        "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
        "            early_stopping(vali_loss, self.model, path)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "            if self.args.lradj != 'TST':\n",
        "                adjust_learning_rate(model_optim, scheduler, epoch + 1, self.args)\n",
        "            else:\n",
        "                print('Updating learning rate to {}'.format(scheduler.get_last_lr()[0]))\n",
        "\n",
        "        best_model_path = path + '/' + 'checkpoint.pth'\n",
        "        self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def test(self, setting, test=0):\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "\n",
        "        if test:\n",
        "            print('loading model')\n",
        "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
        "\n",
        "        preds = []\n",
        "        trues = []\n",
        "        inputx = []\n",
        "        folder_path = './test_results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                            outputs = self.model(batch_x)\n",
        "                        else:\n",
        "                            if self.args.output_attention:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                            else:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                            outputs = self.model(batch_x)\n",
        "                            if self.res_active:\n",
        "                                outputs_res = self.model_res(batch_x)\n",
        "                                outputs = outputs + 0.05*outputs_res\n",
        "                    else:\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                # print(outputs.shape,batch_y.shape)\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                if self.args.last_eval:\n",
        "                    batch_y = batch_y[:,-1,:].unsqueeze(1)\n",
        "                    outputs = outputs[:,-1,:].unsqueeze(1)\n",
        "                outputs = outputs.detach().cpu().numpy()\n",
        "                batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "                preds.append(pred)\n",
        "                trues.append(true)\n",
        "                inputx.append(batch_x.detach().cpu().numpy())\n",
        "                if i % 20 == 0:\n",
        "                    input = batch_x.detach().cpu().numpy()\n",
        "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
        "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
        "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
        "\n",
        "        if self.args.test_flop:\n",
        "            test_params_flop((batch_x.shape[1],batch_x.shape[2]))\n",
        "            exit()\n",
        "        preds = np.array(preds)\n",
        "        trues = np.array(trues)\n",
        "        inputx = np.array(inputx)\n",
        "\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
        "        inputx = inputx.reshape(-1, inputx.shape[-2], inputx.shape[-1])\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        mae, mse, rmse, mape, mspe, rse, corr = metric(preds, trues)\n",
        "        print('mse:{}, mae:{}, rse:{}'.format(mse, mae, rse))\n",
        "        f = open(\"result.txt\", 'a')\n",
        "        f.write(setting + \"  \\n\")\n",
        "        f.write('mse:{}, mae:{}, rse:{}'.format(mse, mae, rse))\n",
        "        f.write('\\n')\n",
        "        f.write('\\n')\n",
        "        f.close()\n",
        "\n",
        "        # np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe,rse, corr]))\n",
        "        np.save(folder_path + 'pred.npy', preds)\n",
        "        # np.save(folder_path + 'true.npy', trues)\n",
        "        # np.save(folder_path + 'x.npy', inputx)\n",
        "        print(outputs.shape, batch_y.shape)\n",
        "        return\n",
        "\n",
        "    def predict(self, setting, load=False):\n",
        "        pred_data, pred_loader = self._get_data(flag='pred')\n",
        "\n",
        "        if load:\n",
        "            path = os.path.join(self.args.checkpoints, setting)\n",
        "            best_model_path = path + '/' + 'checkpoint.pth'\n",
        "            self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        preds = []\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[2]]).float().to(batch_y.device)\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                            outputs = self.model(batch_x)\n",
        "                        else:\n",
        "                            if self.args.output_attention:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                            else:\n",
        "                                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if 'Linear' in self.args.model or 'TST' in self.args.model:\n",
        "                        outputs = self.model(batch_x)\n",
        "                    else:\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                preds.append(pred)\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        np.save(folder_path + 'real_prediction.npy', preds)\n",
        "\n",
        "        return"
      ],
      "metadata": {
        "id": "y3cdio1yej4j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "xtKsN3--sT1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_known_args()[0]\n",
        "args.random_seed=2021\n",
        "args.is_training=1\n",
        "args.model_id='336_96'\n",
        "args.model='PatchTST'\n",
        "args.data='ETTm1'\n",
        "args.root_path='./dataset/'\n",
        "args.data_path='ETTm2.csv'\n",
        "args.features='M'\n",
        "args.target='OT'\n",
        "args.freq='h'\n",
        "args.checkpoints='./checkpoints/'\n",
        "args.seq_len=336\n",
        "args.label_len=0\n",
        "args.pred_len=192\n",
        "args.fc_dropout=0.2\n",
        "args.head_dropout=0.0\n",
        "args.patch_len=16\n",
        "args.stride=8\n",
        "args.padding_patch='end'\n",
        "args.revin=1\n",
        "args.affine=0\n",
        "args.subtract_last=0\n",
        "args.decomposition=0\n",
        "args.kernel_size=25\n",
        "args.individual=0\n",
        "args.embed_type=0\n",
        "args.enc_in=7\n",
        "args.dec_in=7\n",
        "args.c_out=7\n",
        "args.d_model=128\n",
        "args.n_heads=16\n",
        "args.e_layers=3\n",
        "args.d_layers=1\n",
        "args.d_ff=256\n",
        "args.moving_avg=25\n",
        "args.factor=1\n",
        "args.distil=True\n",
        "args.dropout=0.2\n",
        "args.embed='timeF'\n",
        "args.activation='gelu'\n",
        "args.output_attention=False\n",
        "args.do_predict=False\n",
        "args.num_workers=0\n",
        "args.itr=1\n",
        "args.train_epochs=100\n",
        "args.batch_size=128\n",
        "args.patience=10\n",
        "args.learning_rate=0.0001\n",
        "args.des='Exp'\n",
        "args.loss='mse'\n",
        "args.lradj='TST'\n",
        "args.pct_start=0.4\n",
        "args.use_amp=False\n",
        "args.use_gpu=True\n",
        "args.gpu=0\n",
        "args.use_multi_gpu=False\n",
        "args.devices='0,1,2,3'\n",
        "args.test_flop=False\n",
        "args.last_train=False\n",
        "args.last_eval=True\n",
        "args.start=5\n",
        "\n",
        "\n",
        "if args.last_train==True:\n",
        "    args.last_eval=True\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWuT7VX7sSgI",
        "outputId": "b7059da6-bffa-40c7-901c-9c9d74b830c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(random_seed=2021, is_training=1, model_id='336_96', model='PatchTST', data='ETTm1', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=0, pred_len=192, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, last_train=False, last_eval=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fix_seed = args.random_seed\n",
        "random.seed(fix_seed)\n",
        "torch.manual_seed(fix_seed)\n",
        "np.random.seed(fix_seed)\n",
        "\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "\n",
        "if args.use_gpu and args.use_multi_gpu:\n",
        "    args.dvices = args.devices.replace(' ', '')\n",
        "    device_ids = args.devices.split(',')\n",
        "    args.device_ids = [int(id_) for id_ in device_ids]\n",
        "    args.gpu = args.device_ids[0]\n",
        "\n",
        "print('Args in experiment:')\n",
        "print(args)\n",
        "\n",
        "Exp = Exp_Main\n",
        "\n",
        "\n",
        "if args.is_training:\n",
        "    for ii in range(args.itr):\n",
        "        # setting record of experiments\n",
        "        setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "            args.model_id,\n",
        "            args.model,\n",
        "            args.data,\n",
        "            args.features,\n",
        "            args.seq_len,\n",
        "            args.label_len,\n",
        "            args.pred_len,\n",
        "            args.d_model,\n",
        "            args.n_heads,\n",
        "            args.e_layers,\n",
        "            args.d_layers,\n",
        "            args.d_ff,\n",
        "            args.factor,\n",
        "            args.embed,\n",
        "            args.distil,\n",
        "            args.des,ii)\n",
        "\n",
        "        exp = Exp(args)  # set experiments\n",
        "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "        exp.train(setting)\n",
        "\n",
        "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "        exp.test(setting)\n",
        "\n",
        "        if args.do_predict:\n",
        "            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "            exp.predict(setting, True)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "else:\n",
        "    ii = 0\n",
        "    setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n",
        "                                                                                                args.model,\n",
        "                                                                                                args.data,\n",
        "                                                                                                args.features,\n",
        "                                                                                                args.seq_len,\n",
        "                                                                                                args.label_len,\n",
        "                                                                                                args.pred_len,\n",
        "                                                                                                args.d_model,\n",
        "                                                                                                args.n_heads,\n",
        "                                                                                                args.e_layers,\n",
        "                                                                                                args.d_layers,\n",
        "                                                                                                args.d_ff,\n",
        "                                                                                                args.factor,\n",
        "                                                                                                args.embed,\n",
        "                                                                                                args.distil,\n",
        "                                                                                                args.des, ii)\n",
        "\n",
        "    exp = Exp(args)  # set experiments\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting, test=1)\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0QhrgJ7dsHH",
        "outputId": "8f6dd9e1-b611-4fdc-b04a-f598a1acf90f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Args in experiment:\n",
            "Namespace(random_seed=2021, is_training=1, model_id='336_96', model='PatchTST', data='ETTm1', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=0, pred_len=192, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False, last_train=False, last_eval=True)\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : 336_96_PatchTST_ETTm1_ftM_sl336_ll0_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 34033\n",
            "val 11329\n",
            "test 11329\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 1 | loss: 0.3381078\n",
            "\tspeed: 0.1030s/iter; left time: 2718.2736s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 1 | loss: 0.2867628\n",
            "\tspeed: 0.1037s/iter; left time: 2727.3180s\n",
            "Epoch: 1 cost time: 27.421666145324707\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 1, Steps: 265 | Train Loss: 0.4132010 Vali Loss: 0.2413971 Test Loss: 0.3233798\n",
            "Validation loss decreased (inf --> 0.241397).  Saving model ...\n",
            "Updating learning rate to 4.147995888890545e-06\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 2 | loss: 0.5000444\n",
            "\tspeed: 0.2390s/iter; left time: 6246.7735s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 2 | loss: 0.5084180\n",
            "\tspeed: 0.1041s/iter; left time: 2711.3468s\n",
            "Epoch: 2 cost time: 27.594713926315308\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 2, Steps: 265 | Train Loss: 0.3496415 Vali Loss: 0.2316372 Test Loss: 0.3121980\n",
            "Validation loss decreased (0.241397 --> 0.231637).  Saving model ...\n",
            "Updating learning rate to 4.591070939598485e-06\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 3 | loss: 0.2947645\n",
            "\tspeed: 0.2409s/iter; left time: 6232.1316s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 3 | loss: 0.3418125\n",
            "\tspeed: 0.1056s/iter; left time: 2722.1236s\n",
            "Epoch: 3 cost time: 27.937382221221924\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 3, Steps: 265 | Train Loss: 0.3313846 Vali Loss: 0.2269918 Test Loss: 0.3067492\n",
            "Validation loss decreased (0.231637 --> 0.226992).  Saving model ...\n",
            "Updating learning rate to 5.326492931874866e-06\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 4 | loss: 0.3666195\n",
            "\tspeed: 0.2440s/iter; left time: 6248.6501s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 4 | loss: 0.3340293\n",
            "\tspeed: 0.1064s/iter; left time: 2714.4907s\n",
            "Epoch: 4 cost time: 28.16742992401123\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 4, Steps: 265 | Train Loss: 0.3208442 Vali Loss: 0.2271223 Test Loss: 0.3042854\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Updating learning rate to 6.349726889409005e-06\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 5 | loss: 0.3689429\n",
            "\tspeed: 0.2427s/iter; left time: 6150.0584s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 5 | loss: 0.3908220\n",
            "\tspeed: 0.1064s/iter; left time: 2686.0861s\n",
            "Epoch: 5 cost time: 28.14092516899109\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 5, Steps: 265 | Train Loss: 0.3144394 Vali Loss: 0.2234357 Test Loss: 0.3028000\n",
            "Validation loss decreased (0.226992 --> 0.223436).  Saving model ...\n",
            "Updating learning rate to 7.654463044738896e-06\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 6 | loss: 0.2960126\n",
            "\tspeed: 0.3525s/iter; left time: 8838.1293s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 6 | loss: 0.2810479\n",
            "\tspeed: 0.2142s/iter; left time: 5350.5655s\n",
            "Epoch: 6 cost time: 56.65326261520386\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 6, Steps: 265 | Train Loss: 0.2837241 Vali Loss: 0.2396184 Test Loss: 0.3100155\n",
            "EarlyStopping counter: 1 out of 10\n",
            "Updating learning rate to 9.232655748403029e-06\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 7 | loss: 0.3288991\n",
            "\tspeed: 0.4950s/iter; left time: 12281.9949s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 7 | loss: 0.2955338\n",
            "\tspeed: 0.2148s/iter; left time: 5309.0445s\n",
            "Epoch: 7 cost time: 56.72414016723633\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 7, Steps: 265 | Train Loss: 0.2616974 Vali Loss: 0.2598407 Test Loss: 0.3256715\n",
            "EarlyStopping counter: 2 out of 10\n",
            "Updating learning rate to 1.107457308240065e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 8 | loss: 0.2719096\n",
            "\tspeed: 0.4997s/iter; left time: 12265.6483s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 8 | loss: 0.2450461\n",
            "\tspeed: 0.2167s/iter; left time: 5297.3771s\n",
            "Epoch: 8 cost time: 57.31930136680603\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 8, Steps: 265 | Train Loss: 0.2503662 Vali Loss: 0.2565331 Test Loss: 0.3177774\n",
            "EarlyStopping counter: 3 out of 10\n",
            "Updating learning rate to 1.3168856872018862e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 9 | loss: 0.3606686\n",
            "\tspeed: 0.4996s/iter; left time: 12130.5522s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 9 | loss: 0.3031597\n",
            "\tspeed: 0.2158s/iter; left time: 5217.9477s\n",
            "Epoch: 9 cost time: 57.09625720977783\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 9, Steps: 265 | Train Loss: 0.2424283 Vali Loss: 0.2449959 Test Loss: 0.3029210\n",
            "EarlyStopping counter: 4 out of 10\n",
            "Updating learning rate to 1.550259272596464e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 10 | loss: 0.2144380\n",
            "\tspeed: 0.4988s/iter; left time: 11980.0280s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 10 | loss: 0.2429266\n",
            "\tspeed: 0.2155s/iter; left time: 5154.9933s\n",
            "Epoch: 10 cost time: 57.060975313186646\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 10, Steps: 265 | Train Loss: 0.2349928 Vali Loss: 0.2507466 Test Loss: 0.3024915\n",
            "EarlyStopping counter: 5 out of 10\n",
            "Updating learning rate to 1.806138967289881e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 11 | loss: 0.2194771\n",
            "\tspeed: 0.4976s/iter; left time: 11819.0125s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 11 | loss: 0.2358591\n",
            "\tspeed: 0.2152s/iter; left time: 5090.0916s\n",
            "Epoch: 11 cost time: 56.90666389465332\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 11, Steps: 265 | Train Loss: 0.2296619 Vali Loss: 0.2498454 Test Loss: 0.3009429\n",
            "EarlyStopping counter: 6 out of 10\n",
            "Updating learning rate to 2.0829468903294163e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 12 | loss: 0.2226128\n",
            "\tspeed: 0.4977s/iter; left time: 11687.9776s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 12 | loss: 0.2173685\n",
            "\tspeed: 0.2149s/iter; left time: 5025.1071s\n",
            "Epoch: 12 cost time: 56.876873254776\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 12, Steps: 265 | Train Loss: 0.2253567 Vali Loss: 0.2480740 Test Loss: 0.3041088\n",
            "EarlyStopping counter: 7 out of 10\n",
            "Updating learning rate to 2.3789761069391508e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 13 | loss: 0.2225556\n",
            "\tspeed: 0.4973s/iter; left time: 11548.1268s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 13 | loss: 0.2323848\n",
            "\tspeed: 0.2149s/iter; left time: 4969.3098s\n",
            "Epoch: 13 cost time: 56.852187633514404\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 13, Steps: 265 | Train Loss: 0.2224090 Vali Loss: 0.2510834 Test Loss: 0.3032601\n",
            "EarlyStopping counter: 8 out of 10\n",
            "Updating learning rate to 2.692401154325343e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 14 | loss: 0.1840964\n",
            "\tspeed: 0.4970s/iter; left time: 11408.7387s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 14 | loss: 0.2078536\n",
            "\tspeed: 0.2147s/iter; left time: 4906.0846s\n",
            "Epoch: 14 cost time: 56.807759046554565\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 14, Steps: 265 | Train Loss: 0.2186565 Vali Loss: 0.2501580 Test Loss: 0.3052125\n",
            "EarlyStopping counter: 9 out of 10\n",
            "Updating learning rate to 3.0212892983843068e-05\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 100, epoch: 15 | loss: 0.2186088\n",
            "\tspeed: 0.4970s/iter; left time: 11276.5969s\n",
            "torch.Size([128, 192, 7]) torch.Size([128, 192, 7])\n",
            "\titers: 200, epoch: 15 | loss: 0.2226311\n",
            "\tspeed: 0.2153s/iter; left time: 4863.8001s\n",
            "Epoch: 15 cost time: 56.93291473388672\n",
            "alpha: 0.0\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "torch.Size([128, 1, 7]) torch.Size([128, 1, 7])\n",
            "Epoch: 15, Steps: 265 | Train Loss: 0.2156949 Vali Loss: 0.2571833 Test Loss: 0.3112471\n",
            "EarlyStopping counter: 10 out of 10\n",
            "Early stopping\n",
            ">>>>>>>testing : 336_96_PatchTST_ETTm1_ftM_sl336_ll0_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 11329\n",
            "mse:0.3108904957771301, mae:0.3690776824951172, rse:0.45123714208602905\n",
            "(128, 1, 7) (128, 1, 7)\n"
          ]
        }
      ]
    }
  ]
}